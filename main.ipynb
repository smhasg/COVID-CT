{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow -U\n",
    "#!pip install opencv-python\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import cv2\n",
    "import os  \n",
    "# import tensorflow.keras as keras \n",
    "\n",
    "# from opencv import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read DS2 masks \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "\n",
    "# cdf = pd.DataFrame( )\n",
    "train_img  ,mask_img,val_img = [] , [], [] \n",
    "\n",
    "root_dir = \"/home/smhasg/Desktop/projects/COIVD19/myproject/DS2/\"\n",
    "train_dir = \"/home/smhasg/Desktop/projects/COIVD19/myproject/DS2/tr_im/\"\n",
    "mask_dir = '/home/smhasg/Desktop/projects/COIVD19/myproject/DS2/tr_mask/'\n",
    "val_dir = \"/home/smhasg/Desktop/projects/COIVD19/myproject/DS2/val_im/\"\n",
    "\n",
    "paths = [train_dir,mask_dir,val_dir] \n",
    "\n",
    "for image in os.listdir(train_dir):\n",
    "    # print (image)\n",
    "    if image.endswith(\".jpg\"):\n",
    "        img =  cv2.imread(f\"{train_dir}/{image}\")\n",
    "        train_img.append(img)\n",
    "\n",
    "for image in os.listdir(mask_dir):\n",
    "    # print (image)\n",
    "    if image.endswith(\".jpg\"):\n",
    "        img =  cv2.imread(f\"{mask_dir}/{image}\")\n",
    "        mask_img.append(img)\n",
    "\n",
    "for image in os.listdir(val_dir):\n",
    "    # print (image)\n",
    "    if image.endswith(\".jpg\"):\n",
    "        img =  cv2.imread(f\"{val_dir}/{image}\")\n",
    "        val_img.append(img)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask_img[1])\n",
    "len(mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img = np.array(train_img)\n",
    "train_img = train_img/255 \n",
    "train_img = train_img.astype(np.float32)\n",
    "type(train_img)\n",
    "train_img.dtype\n",
    "train_img.shape\n",
    "\n",
    "mask_img = np.array(mask_img)\n",
    "mask_img = mask_img/255 \n",
    "mask_img = mask_img.astype(np.float32)\n",
    "type(mask_img)\n",
    "mask_img.shape\n",
    "mask_img.dtype\n",
    "\n",
    "val_img = np.array(val_img)\n",
    "val_img = val_img /255 \n",
    "val_img = val_img.astype(np.float32)\n",
    "type(val_img)\n",
    "val_img.shape\n",
    "val_img.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read DS1\n",
    "\n",
    "# # Get the file paths\n",
    "# covid_img ,noncovid_img= [], [] \n",
    "\n",
    "# root_dir = \"/home/smhasg/Desktop/projects/COIVD19/myproject/DS1/Images-processed\"\n",
    "# covid_dir = \"/home/smhasg/Desktop/projects/COIVD19/myproject/DS1/Images-processed/CT_COVID/\"\n",
    "# noncovid_dir = '/home/smhasg/Desktop/projects/COIVD19/myproject/DS1/Images-processed/CT_NonCOVID/'\n",
    "\n",
    "# paths = [covid_dir,noncovid_dir] \n",
    "\n",
    "# for image in os.listdir(covid_dir):\n",
    "#     # print (image)\n",
    "#     if image.endswith(\".png\"):\n",
    "#         img =  cv2.imread(f\"{covid_dir}/{image}\")\n",
    "#         covid_img.append(img)\n",
    "\n",
    "# for image in os.listdir(noncovid_dir):\n",
    "#     # print (image)\n",
    "#     if image.endswith(\".png\"):\n",
    "#         img =  cv2.imread(f\"{noncovid_dir}/{image}\")\n",
    "#         noncovid_img.append(img)\n",
    "\n",
    "\n",
    "# covid_img_size = 0\n",
    "# for i in covid_img :\n",
    "#      # print(i.shape)\n",
    "#      covid_img_size+=1\n",
    "# print(f'covid_img_size : {covid_img_size}')\n",
    "\n",
    "# noncovid_img_size = 0\n",
    "# for i in noncovid_img :\n",
    "#      # print(i.shape)\n",
    "#      noncovid_img_size+=1\n",
    "# print(f'noncovid_img_size : {noncovid_img_size}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(covid_img[1])\n",
    "# plt.imshow(noncovid_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(covid_img)):\n",
    "#      print(covid_img[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alter native for image read \n",
    "# from PIL import Image\n",
    "# from numpy import asarray\n",
    "# import os \n",
    "# import numpy as np \n",
    "# from tqdm import tqdm\n",
    "\n",
    "# root_path = '/home/smhasg/Desktop/projects/COIVD19/myproject/DS1/Images-processed/'\n",
    "# # read data and concatenate\n",
    "# labels = []\n",
    "\n",
    "# def read_data():\n",
    "#   os.chdir(root_path)\n",
    "#   sub_dirs = os.listdir()\n",
    "#   result = []\n",
    "#   for path in sub_dirs:\n",
    "#     images = []\n",
    "#     sub_dir = os.path.join(root_path, path)\n",
    "#     os.chdir(sub_dir)\n",
    "#     list_of_files = os.listdir()\n",
    "#     for i in tqdm(list_of_files):\n",
    "#       tmp = Image.open(i)\n",
    "#      # tmp = cv2.resize(tmp, (128, 128))\n",
    "#      #  if len(tmp.shape) > 2:\n",
    "#      #      tmp = tmp[:,:,0]\n",
    "#      #  else:\n",
    "#       tmp = tmp\n",
    "      \n",
    "#       images.append(tmp)\n",
    "#       # np.array(images, tmp )\n",
    "\n",
    "#     result.append(images)\n",
    "#   im = np.asarray(images)\n",
    "#   return result\n",
    "# # load the image\n",
    "\n",
    "# # image = Image.open('kolala.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #alternative for im read \n",
    "# import matplotlib.pyplot as plt \n",
    "# os.chdir(root_path)\n",
    "# sub_dirs = os.listdir()64\n",
    "# for path in sub_dirs:\n",
    "#   labels.append(path)\n",
    "#   sub_dir = os.path.join(root_path, path)\n",
    "#   os.chdir(sub_dir)\n",
    "#   img = [] \n",
    "  \n",
    "#   plt.figure(figsize=(10, 10))\n",
    "#   ii = 1\n",
    "#   for i in os.listdir()[:5]:\n",
    "#     tmp = Image.open(i)\n",
    "#     plt.subplot(1, 5, ii)\n",
    "#     plt.imshow(tmp, cmap='binary')\n",
    "#     plt.title(i)\n",
    "#     ii += 1\n",
    "  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 00:31:51.068401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/smhasg/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-09 00:31:51.068459: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-09 00:31:53.331007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/smhasg/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-09 00:31:53.331378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/smhasg/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-09 00:31:53.331403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "# input = keras.layers.Input(shape=(512, 512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in covid_img:\n",
    "# # covid_img = np.array(covid_img)\n",
    "#      #print(type(i))\n",
    "# plt.imshow(covid_img[2])\n",
    "# type(covid_img)\n",
    "# covid_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 00:32:02.061349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/smhasg/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-09 00:32:02.063105: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-09 00:32:02.063191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (smhasg-comp): /proc/driver/nvidia/version does not exist\n",
      "2023-02-09 00:32:02.141755: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 314572800 exceeds 10% of free system memory.\n",
      "2023-02-09 00:32:02.383382: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 6710886400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# my model \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "input = keras.layers.Input(shape=train_img.shape)\n",
    "# encoder 14 layers  \n",
    "\n",
    "encoder = models.Sequential()\n",
    "\n",
    "encoder.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=train_img.shape[1:], padding='same')(train_img))\n",
    "encoder.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "# encoder.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
    "encoder.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
    "encoder.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
    "encoder.add(layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
    "encoder.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "encoder.add(layers.Conv2D(filters= 3, kernel_size=(1, 1), activation='sigmoid', padding='same')) # filters= mask_img.shape[-1]\n",
    "#sample decoder \n",
    "# encoder.add(keras.layers.Conv2D(1,(1,1)))\n",
    "# encoder.add(keras.layers.Conv2D(512,(1,1)))\n",
    "\n",
    "\n",
    "# x = keras.layers.Conv2D(512,(3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "# x = keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2DTranspose(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2DTranspose(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2DTranspose(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2DTranspose(16, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "# x= keras.layers.Flatten(x)\n",
    "# upsampling  \n",
    "#.\n",
    "#.\n",
    "#.\n",
    "#.\n",
    "\n",
    "\n",
    "# reconstructor 14 layers \n",
    " \n",
    "# x = keras.layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "# x = keras.layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# segmentation 14 layers  \n",
    "#.\n",
    "#.\n",
    "#.\n",
    "#.\n",
    "\n",
    "#  classification 14 layers  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 256, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 128, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 64, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 32, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 1024)      4719616   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 1024)      9438208   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 3)         3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,846,275\n",
      "Trainable params: 18,846,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple unet model \n",
    "# keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.compile( optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.Recall(),\n",
    "                       tf.keras.metrics.Precision()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 00:26:33.297562: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 314572800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 32, 32, 3) vs (None, 512, 512, 3)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8128/2966192426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m encoded = encoder.fit(train_img, mask_img,epochs=20,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=(val_img,val_img))\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/smhasg/.local/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 32, 32, 3) vs (None, 512, 512, 3)).\n"
     ]
    }
   ],
   "source": [
    "encoded = encoder.fit(train_img, mask_img,epochs=20,\n",
    "                    validation_data=(val_img,val_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 3) dtype=float32 (created by layer 'sequential')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(input ,x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='adam',loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 22:51:27.615157: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 314572800 exceeds 10% of free system memory.\n",
      "2023-02-08 22:51:27.872792: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 314572800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 99ms/step - loss: 0.4460\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.4460\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 0.4460\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4460\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 115ms/step - loss: 0.4460\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4460\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4460\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.4460\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 102ms/step - loss: 0.4460\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c0128f490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_img,mask_img,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "\n",
    "model = get_segmentation_model(input , x ) # this would build the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "\n",
    "input = keras.layers.Input(shape=(512, 512,3))\n",
    "\n",
    "# Encoder\n",
    "x = keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(train_img)\n",
    "x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = keras.Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
